{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "453dace9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "영어 쿼리를 입력하세요.Hello My name is Youngchae\n",
      "rank\tIndex\tscore\tsentence\n",
      "1\t679\t0.5\tMy name is Mike.\n",
      "2\t526\t0.2857142857142857\tBob is my brother.\n",
      "3\t538\t0.2857142857142857\tMy hobby is traveling.\n",
      "4\t453\t0.25\tMy mother is sketching them.\n",
      "5\t241\t0.2222222222222222\tMy father is running with So-ra.\n",
      "6\t336\t0.2222222222222222\tMy family is at the park.\n",
      "7\t212\t0.2\tMy sister Betty is waiting for me.\n",
      "8\t505\t0.18181818181818182\tMy little sister Annie is five years old.\n",
      "9\t610\t0.15384615384615385\tI would raise my voice and yell, \"LUNCH IS READY!\"\n",
      "10\t190\t0.14285714285714285\tIt is Sunday.\n"
     ]
    }
   ],
   "source": [
    "import operator\n",
    "\n",
    "# Preprocess the input search sentence\n",
    "def preprocess(sentence): \n",
    "    # Split the sentence into tokens\n",
    "    preprocessed_sentence = sentence.strip().split(\" \")\n",
    "    return preprocessed_sentence\n",
    "\n",
    "# Return token sets for each sentence in the file\n",
    "def indexing(file_name):\n",
    "    file_tokens_pairs = []\n",
    "    \n",
    "    # Read lines from the specified file\n",
    "    lines = open(file_name, \"r\", encoding=\"utf8\").readlines()\n",
    "    for line in lines:\n",
    "        tokens = preprocess(line) # Preprocess each line\n",
    "        file_tokens_pairs.append(tokens)\n",
    "        \n",
    "    # Return a list of token sets for all sentences in the file\n",
    "    return file_tokens_pairs \n",
    "\n",
    "# Dictionary to store file IDs and similarity scores between the query and sentences\n",
    "def calc_similarity(preprocessed_query, preprocessed_sentences):\n",
    "    score_dict = {}\n",
    "    num_sentences = len(preprocessed_sentences)\n",
    "\n",
    "    for i in range(num_sentences):\n",
    "        # Convert tokens to lowercase for case-insensitive similarity\n",
    "        file_tokens = []\n",
    "        for token in preprocessed_sentences[i]:\n",
    "            file_tokens.append(token.lower())\n",
    "\n",
    "        query_tokens = []\n",
    "        for token in preprocessed_query:\n",
    "            query_tokens.append(token.lower())\n",
    "            \n",
    "        file_token_set = set(file_tokens) # Tokens set in a file\n",
    "        query_token_set = set(query_tokens) # Tokens set in a query\n",
    "\n",
    "        # Union of tokens in query and sentence\n",
    "        all_tokens = query_token_set | file_token_set\n",
    "        # Intersection of tokens in query and sentence\n",
    "        same_tokens = query_token_set & file_token_set\n",
    "\n",
    "        # Calulate the similarity\n",
    "        similarity = len(same_tokens) / len(all_tokens)\n",
    "        score_dict[i] = similarity # Store the similarity in the dictionary\n",
    "\n",
    "    return score_dict\n",
    "\n",
    "# 1. Indexing : Read and tokenize sentences from a file\n",
    "file_name = \"jhe-koen-dev.en\"\n",
    "file_tokens_pairs = indexing(file_name)\n",
    "\n",
    "# 2. Input the query\n",
    "query = input(\"영어 쿼리를 입력하세요.\")\n",
    "\n",
    "preprocessed_query = preprocess(query) # Preprocess the query\n",
    "query_token_set = set(preprocessed_query) # Create a set of tokens from the query \n",
    "\n",
    "\n",
    "# 3. Calculate similarities based on a same token set\n",
    "score_dict = calc_similarity(query_token_set, file_tokens_pairs)\n",
    "\n",
    "# 4. Sort the similarity list\n",
    "sorted_score_list = sorted(score_dict.items(), key = operator.itemgetter(1), reverse=True)\n",
    "\n",
    "# 5. Print the result\n",
    "if sorted_score_list[0][1] == 0.0:\n",
    "    print(\"There is no similar sentence.\")\n",
    "else:\n",
    "    print(\"rank\", \"Index\", \"score\", \"sentence\", sep = \"\\t\")\n",
    "    rank = 1\n",
    "    for i, score  in sorted_score_list:\n",
    "        # Print the most similar sentences\n",
    "        print(rank, i, score, ' '.join(file_tokens_pairs[i]), sep = \"\\t\")\n",
    "        if rank == 10:\n",
    "            break\n",
    "        rank = rank + 1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc85c84e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
